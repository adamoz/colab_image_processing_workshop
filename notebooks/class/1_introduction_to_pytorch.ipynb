{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"1_introduction_to_pytorch.ipynb","provenance":[],"collapsed_sections":["N87uuNzJXh7C","gHziua43DUWP","gZtgAdtqDUWZ","bVX2i6RsDUWb","-XI3OhNADUW7","Eoo-sdIuDUXM","reNVK0QcDUXi","pidLZWwFDUX2","p5byVoq3DUX3","uLLB-HalDUX5","lc_zD9uYDUYS","kQCQYhvMDUYo"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"N87uuNzJXh7C","colab_type":"text"},"source":["# Setup of Colab Environment\n"]},{"cell_type":"markdown","metadata":{"id":"C3jqbs9Br1yT","colab_type":"text"},"source":["Every Colab runs it's own instance on cloud. We need setup workshop enviroment in those steps:  \n","* Setup GPU instance: Runtime ->  Change runtime type \n","* Install workshop package with all requiremetns from git\n","* Import all packages\n","* Mount GDrive  "]},{"cell_type":"code","metadata":{"id":"_3ClUAZZZtxm","colab_type":"code","colab":{}},"source":["!pip install git+https://github.com/adamoz/colab_image_processing_workshop.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7d2eq2PaAQR","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","from google.colab import files\n","from shutil import rmtree\n","import os\n","\n","import numpy as np\n","import torch\n","from torch.optim import SGD\n","from torch.nn import Linear, MSELoss, Tanh"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVh_U9jRaIBZ","colab_type":"code","colab":{}},"source":["drive.mount('./drive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qjcw-k7g-sD","colab_type":"code","colab":{}},"source":["os.listdir('./drive/My Drive/ml_college_data')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gHziua43DUWP","colab_type":"text"},"source":["# Introduction to PyTorch\n","---"]},{"cell_type":"markdown","metadata":{"id":"IyROgBNDsXkK","colab_type":"text"},"source":["\n","[PyTorch](https://pytorch.org/docs/stable/index.html) is a framework for building trainable (automatically differentiable) directed acyclic graphs in dynamic manner (in cotrast with e.g. Tensorflow which builds static dags).   \n","\n","PyTorch's main building block are tensors (and it's highlevel abstractions e.g. `torch.nn` layers) and operations upon those tensors. Using PyTorch we can define minimization problems, which can be solved using `torch` optimization modules.\n","\n","**Overvoew of PyTorch package**\n"," - `torch.nn`  Highl-level abstractions useful for designing neural network architectures including various neural network layer types, loss functions and containers for more complex models.\n"," - `torch.nn.functional`  Similar as torch.nn, not defined in class manner but functional.\n"," - `torch.nn.init` Set of methods used for initialization of torch Tensor.\n"," - `torch.optim` Module with various optimizers and learning rate schedulers for training of neural networks.\n"," - `torch.utils.data` Collection of classes for data manipulation.\n"," - `torch.autograd`  Reverse automatic differentiation system which enables automatical computation of the gradients using the chain rule."]},{"cell_type":"markdown","metadata":{"id":"gZtgAdtqDUWZ","colab_type":"text"},"source":["## PyTorch Tensors"]},{"cell_type":"markdown","metadata":{"id":"bVX2i6RsDUWb","colab_type":"text"},"source":["### Analogy with Numpy\n","We can use similar methods as in NumPy to initialze and manipulate with tensors."]},{"cell_type":"code","metadata":{"id":"BdcIeZS1DUWf","colab_type":"code","colab":{}},"source":["np.zeros([3, 3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gfJDmSIDUWi","colab_type":"code","colab":{}},"source":["torch.zeros([3, 3], dtype=torch.long, device=torch.device('cpu'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLlS2I-wDUWl","colab_type":"code","colab":{}},"source":["np.random.rand(3, 3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaG15N9wDUWo","colab_type":"code","colab":{}},"source":["torch.rand(3, 3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xirqDkctDUWr","colab_type":"code","colab":{}},"source":["numpy_tensor = np.array([[1, 2] ,[3, 4]], dtype=np.float)\n","numpy_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xutZrXkDUWu","colab_type":"code","colab":{}},"source":["torch_tensor = torch.tensor([[1, 2] ,[3, 4]], dtype=torch.float)\n","torch_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EIz7D7BtDUWx","colab_type":"code","colab":{}},"source":["numpy_tensor.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9seDvTuYDUWz","colab_type":"code","colab":{}},"source":["torch_tensor.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLxfX9Q1DUW2","colab_type":"code","colab":{}},"source":["torch_tensor.numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gnuqSSmPDUW4","colab_type":"code","colab":{}},"source":["torch.tensor(numpy_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-XI3OhNADUW7","colab_type":"text"},"source":["### Basic operations with tensors"]},{"cell_type":"code","metadata":{"id":"jqozYOweDUW8","colab_type":"code","colab":{}},"source":["torch_tensor = torch.tensor([[1, 2] ,[3, 4]], dtype=torch.float)\n","torch_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EexfioZsDUW-","colab_type":"code","colab":{}},"source":["torch_tensor + torch_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RAPEJ-EjDUXB","colab_type":"code","colab":{}},"source":["torch_tensor + 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKf5mzxJDUXE","colab_type":"code","colab":{}},"source":["torch_tensor * torch_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Amr3Gk4wDUXG","colab_type":"code","colab":{}},"source":["torch_tensor.mm(torch_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OJmRoP6DUXJ","colab_type":"code","colab":{}},"source":["torch.nn.init.normal_(torch_tensor)\n","torch_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eoo-sdIuDUXM","colab_type":"text"},"source":["### Work with shape"]},{"cell_type":"code","metadata":{"id":"DTpvJK75DUXN","colab_type":"code","colab":{}},"source":["torch_tensor = torch.tensor([[1, 2] ,[3, 4]], dtype=torch.float)\n","torch_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aCFIEu2RDUXS","colab_type":"code","colab":{}},"source":["torch_tensor.view(-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1c6rThcFDUXX","colab_type":"code","colab":{}},"source":["torch_tensor[1, :]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ylHsNn85DUXZ","colab_type":"code","colab":{}},"source":["torch.cat([torch_tensor, torch_tensor], dim=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y8qAYD-IDUXb","colab_type":"code","colab":{}},"source":["torch.unsqueeze(torch_tensor, 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"-aXppE8ADUXe","colab_type":"code","colab":{}},"source":["torch.transpose(torch_tensor, 1, 0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"reNVK0QcDUXi","colab_type":"text"},"source":["### Special tensor properties\n","All those attributes are related to optimizations we can use over tensors.\n","\n"," - `.requires_grad`  Indication that we want to compute gradinet for this tensor. Pytorch will start to track all operations on it.\n"," - `.grad` After calling `y.backward()`, we have in `x.grad` (in case it requires_grad) gradinet defined as $\\frac{dy}{dx}$.\n"," - `.grad_fn` Reference to function that has created the Tensor."]},{"cell_type":"code","metadata":{"id":"_BzHcv6ADUXj","colab_type":"code","colab":{}},"source":["x = torch.tensor([[5]], dtype=torch.float, requires_grad=True)\n","x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZWM9C-xiDUXl","colab_type":"code","colab":{}},"source":["x_pow3 =  torch.pow(x, 3)\n","x_pow3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wN6j4ioaDUXq","colab_type":"code","colab":{}},"source":["x_pow3.grad_fn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mEog3hN1DUXs","colab_type":"code","colab":{}},"source":["x_pow3.requires_grad"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BFi9l1IXDUXu","colab_type":"code","colab":{}},"source":["x_pow3.grad is None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TlzcespIDUXw","colab_type":"text"},"source":["Let's compute gradinet of `x_pow3` variable with respect to all `torch.Tensor`s with `.require_grad=True`.\n","To calculate the gradients, we need to run the `x_pow3.backward()`.  \n","This will calculate the gradient for `x_po3` with respect to `x`\n","\n","$$\n","\\frac{\\partial x^3}{\\partial x} = 3x^2\n","$$"]},{"cell_type":"code","metadata":{"id":"62ewQYV_DUXx","colab_type":"code","outputId":"21373727-9658-4f0d-e658-ddf7ec8ba371","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x_pow3.backward()\n","x.grad"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[75.]])"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"markdown","metadata":{"id":"ajXugWrdDUXz","colab_type":"text"},"source":["This is way how to stop collecting gradinet information"]},{"cell_type":"code","metadata":{"id":"MV6quIdQDUXz","colab_type":"code","outputId":"d2be5e6d-da4c-4cfb-e1c0-1ae7135bf887","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["with torch.no_grad():\n","    print((x * x).requires_grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hPiazbqoDUX1","colab_type":"text"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"pidLZWwFDUX2","colab_type":"text"},"source":["## Neural Network Definition\n","PyTorch enables definition of neural networks with several level of abstraction. Let's eplore them.."]},{"cell_type":"markdown","metadata":{"id":"p5byVoq3DUX3","colab_type":"text"},"source":["### Data"]},{"cell_type":"code","metadata":{"id":"QhCjnDs0DUX3","colab_type":"code","colab":{}},"source":["input_batch = torch.tensor([[0.20, 0.15],\n","                            [0.30, 0.20],\n","                            [0.86, 0.99],\n","                            [0.91, 0.88]])\n","\n","label_batch = torch.tensor([[1.],\n","                            [1.],\n","                            [-1.],\n","                            [-1.]])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uLLB-HalDUX5","colab_type":"text"},"source":["### Low level approach\n","Using just `torch.Tensor` and `torch.autograd`."]},{"cell_type":"code","metadata":{"id":"nY2Uky2uDUX6","colab_type":"code","colab":{}},"source":["learning_rate = 1e-3\n","training_iterations = 55000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvnOINNsDUX8","colab_type":"code","colab":{}},"source":["# Define trainable parameters.\n","w1 = torch.randn(2, 1, dtype=torch.float, requires_grad=True, device=torch.device(\"cpu\"))\n","w2 = torch.randn(1, 1, dtype=torch.float, requires_grad=True, device=torch.device(\"cpu\"))\n","w1, w2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtigtWv9duKZ","colab_type":"code","colab":{}},"source":["##############\n","# Playground #\n","##############"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ew8XOf5qDUX-","colab_type":"code","colab":{}},"source":["# After each iteration, we adjust w1 and w2 parameters.\n","for training_iteration in range(training_iterations):\n","    # Here is actual forward pass through simple nn with 2 layers defines by w1 and w2.\n","    prediction = input_batch.mm(w1)\n","    prediction = torch.tanh(prediction)\n","    prediction = prediction.mm(w2)\n","    prediction = torch.tanh(prediction)\n","    \n","    # We can calculate err as mean square error, we need to get single scalar number for optimizer.\n","    loss = (prediction - label_batch).pow(2).mean()\n","    if training_iteration % 5000 == 0:\n","        print(training_iteration, loss.item())\n","\n","    # Here we compute all the gradients of variables\n","    loss.backward()\n","    \n","    # We don't want to collect gradient information for optimization steps.\n","    with torch.no_grad():\n","        w1 -= learning_rate * w1.grad\n","        w2 -= learning_rate * w2.grad\n","        # Clear gradients for next interation, we don't want to cummulate it.\n","        w1.grad.zero_()\n","        w2.grad.zero_()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IhsWt3D2DUYA","colab_type":"code","colab":{}},"source":["# Check predictions.\n","prediction = input_batch.mm(w1)\n","prediction = torch.tanh(prediction)\n","prediction = prediction.mm(w2)\n","prediction = torch.tanh(prediction)\n","prediction"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hwy7qVRBDUYC","colab_type":"code","colab":{}},"source":["torch.save({'w1': w1, 'w2': w2}, './drive/My Drive/ml_college_data/models/ckpt.pth')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jn0wE23uDUYD","colab_type":"code","colab":{}},"source":["state_dict = torch.load('./drive/My Drive/ml_college_data/models/ckpt.pth')\n","w1.data = state_dict['w1']\n","w2.data = state_dict['w2']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lc_zD9uYDUYS","colab_type":"text"},"source":["### Container approach with torch.nn and  torch.optim"]},{"cell_type":"code","metadata":{"id":"CoEts2EnDUYV","colab_type":"code","colab":{}},"source":["learning_rate = 1e-3\n","training_iterations = 55000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUFbW8t6DUYX","colab_type":"code","colab":{}},"source":["class SimpleNN(torch.nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.layer_1 = Linear(2, 1)\n","        self.layer_2 = Linear(1, 1)\n","        \n","    def forward(self, input_batch):\n","        prediction = self.layer_1(input_batch)\n","        prediction = torch.tanh(prediction)\n","        prediction = self.layer_2(prediction)\n","        prediction = torch.tanh(prediction)\n","        return prediction\n","\n","simple_nn = SimpleNN()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hUwxRY7WDUYZ","colab_type":"code","colab":{}},"source":["list(simple_nn.named_parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-sgE9eLHDUYb","colab_type":"code","colab":{}},"source":["loss_fce = MSELoss(reduction='sum')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"blxJi9ezDUYd","colab_type":"code","colab":{}},"source":["optimizer = SGD(simple_nn.parameters(), lr=learning_rate, momentum=0.9)\n","optimizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9ixdWJ7DUYi","colab_type":"code","colab":{}},"source":["for training_iteration in range(training_iterations):\n","    prediction = simple_nn(input_batch)\n","    \n","    loss = loss_fce(prediction, label_batch)\n","    if training_iteration % 5000 == 0:\n","        print(training_iteration, loss.item())\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1T9vkVuXDUYk","colab_type":"code","colab":{}},"source":["simple_nn(input_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"moSYyw4_DUYl","colab_type":"code","colab":{}},"source":["simple_nn.load_state_dict(simple_nn.state_dict())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kQCQYhvMDUYo","colab_type":"text"},"source":["### Container approach with torch.nn.Sequential"]},{"cell_type":"code","metadata":{"id":"e5I1-4WwDUYo","colab_type":"code","colab":{}},"source":["learning_rate = 1e-3\n","training_iterations = 55000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W0xGxXE9DUYq","colab_type":"code","colab":{}},"source":["simple_nn_seq = torch.nn.Sequential(\n","    Linear(2, 1),\n","    Tanh(),\n","    Linear(1, 1),\n","    Tanh()\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ug4Yd3ODUYr","colab_type":"code","colab":{}},"source":["loss_fce = MSELoss(reduction='sum')\n","optimizer = SGD(simple_nn_seq.parameters(), lr=learning_rate, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tM5ZL9PuDUYx","colab_type":"code","colab":{}},"source":["for training_iteration in range(training_iterations):\n","    prediction = simple_nn_seq(input_batch)\n","    \n","    loss = loss_fce(prediction, label_batch)\n","    if training_iteration % 5000 == 0:\n","        print(training_iteration, loss.item())\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TugZv4NXDUY1","colab_type":"code","colab":{}},"source":["simple_nn_seq(input_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KOpx-AkEDUY4","colab_type":"text"},"source":["---"]}]}